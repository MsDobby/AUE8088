LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2,3]
  | Name     | Type             | Params
----------------------------------------------
0 | model    | ResNet           | 11.3 M
1 | loss_fn  | CrossEntropyLoss | 0
2 | accuracy | MyF1Score        | 0
----------------------------------------------
11.3 M    Trainable params
0         Non-trainable params
11.3 M    Total params
45.116    Total estimated model params size (MB)
Sanity Checking: |                                                                                                                               | 0/? [00:00<?, ?it/s][34m[1m[Val]	 root dir: /home/mmc-server4/Server/Datasets_hdd/tiny-imagenet-200/tiny-imagenet-200/val	 | # of samples: 10,000
[34m[1m[Train]	 root dir: /home/mmc-server4/Server/Datasets_hdd/tiny-imagenet-200/tiny-imagenet-200/train	 | # of samples: 100,000
Training: |                                                                                                                                      | 0/? [00:00<?, ?it/s][34m[1mACCELERATOR[39m[22m: gpu
[34m[1mBATCH_SIZE[39m[22m: 512
[34m[1mDATASET_ROOT_PATH[39m[22m: /home/mmc-server4/Server/Datasets_hdd/tiny-imagenet-200/
[34m[1mDEVICES[39m[22m: [2]
[34m[1mIMAGE_FLIP_PROB[39m[22m: 0.5
[34m[1mIMAGE_MEAN[39m[22m: [0.4802, 0.4481, 0.3975]
[34m[1mIMAGE_NUM_CROPS[39m[22m: 64
[34m[1mIMAGE_PAD_CROPS[39m[22m: 4
[34m[1mIMAGE_ROTATION[39m[22m: 20
[34m[1mIMAGE_STD[39m[22m: [0.2302, 0.2265, 0.2262]
[34m[1mMODEL_NAME[39m[22m: resnet18
[34m[1mNUM_CLASSES[39m[22m: 200
[34m[1mNUM_EPOCHS[39m[22m: 40
[34m[1mNUM_WORKERS[39m[22m: 8
[34m[1mOPTIMIZER_PARAMS[39m[22m: {'type': 'SGD', 'lr': 0.005, 'momentum': 0.9}
[34m[1mPRECISION_STR[39m[22m: 32-true
[34m[1mSCHEDULER_PARAMS[39m[22m: {'type': 'MultiStepLR', 'milestones': [30, 35], 'gamma': 0.2}
[34m[1mVAL_EVERY_N_EPOCH[39m[22m: 1
[34m[1mWANDB_ENTITY[39m[22m: ophd
[34m[1mWANDB_IMG_LOG_FREQ[39m[22m: 50
[34m[1mWANDB_NAME[39m[22m: resnet18-B512-SGD-MultiStepLR5.0E-03
[34m[1mWANDB_PROJECT[39m[22m: aue8088-pa1
[34m[1mWANDB_SAVE_DIR[39m[22m: wandb/
















































Epoch 0: 100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████| 196/196 [01:39<00:00,  1.97it/s, v_num=gvyg]





















































Epoch 1: 100%|███████████████████████████████| 196/196 [01:38<00:00,  1.98it/s, v_num=gvyg, loss/val=4.880, accuracy/val=nan.0, loss/train=5.140, accuracy/train=nan.0]






















































Epoch 2: 100%|███████████████████████████████| 196/196 [01:39<00:00,  1.97it/s, v_num=gvyg, loss/val=4.530, accuracy/val=nan.0, loss/train=4.710, accuracy/train=nan.0]





















































Epoch 3: 100%|███████████████████████████████| 196/196 [01:39<00:00,  1.97it/s, v_num=gvyg, loss/val=4.260, accuracy/val=nan.0, loss/train=4.390, accuracy/train=nan.0]





















































Epoch 4: 100%|███████████████████████████████| 196/196 [01:39<00:00,  1.97it/s, v_num=gvyg, loss/val=4.030, accuracy/val=nan.0, loss/train=4.140, accuracy/train=nan.0]






















































Epoch 5: 100%|███████████████████████████████| 196/196 [01:40<00:00,  1.96it/s, v_num=gvyg, loss/val=3.870, accuracy/val=nan.0, loss/train=3.930, accuracy/train=nan.0]





















































Epoch 6: 100%|███████████████████████████████| 196/196 [01:39<00:00,  1.96it/s, v_num=gvyg, loss/val=3.760, accuracy/val=nan.0, loss/train=3.750, accuracy/train=nan.0]






















































Epoch 7: 100%|███████████████████████████████| 196/196 [01:39<00:00,  1.96it/s, v_num=gvyg, loss/val=3.700, accuracy/val=nan.0, loss/train=3.620, accuracy/train=nan.0]






















































Epoch 8: 100%|███████████████████████████████| 196/196 [01:40<00:00,  1.96it/s, v_num=gvyg, loss/val=3.540, accuracy/val=nan.0, loss/train=3.500, accuracy/train=nan.0]





















































Epoch 9: 100%|███████████████████████████████| 196/196 [01:39<00:00,  1.96it/s, v_num=gvyg, loss/val=3.490, accuracy/val=nan.0, loss/train=3.400, accuracy/train=nan.0]





















































Epoch 10: 100%|██████████████████████████████| 196/196 [01:39<00:00,  1.96it/s, v_num=gvyg, loss/val=3.390, accuracy/val=nan.0, loss/train=3.320, accuracy/train=nan.0]
















































Epoch 11: 100%|██████████████████████████████| 196/196 [01:39<00:00,  1.96it/s, v_num=gvyg, loss/val=3.330, accuracy/val=nan.0, loss/train=3.230, accuracy/train=nan.0]






















































Epoch 12: 100%|██████████████████████████████| 196/196 [01:40<00:00,  1.96it/s, v_num=gvyg, loss/val=3.260, accuracy/val=nan.0, loss/train=3.160, accuracy/train=nan.0]





















































Epoch 13: 100%|██████████████████████████████| 196/196 [01:40<00:00,  1.96it/s, v_num=gvyg, loss/val=3.220, accuracy/val=nan.0, loss/train=3.090, accuracy/train=nan.0]






















































Epoch 14: 100%|██████████████████████████████| 196/196 [01:40<00:00,  1.95it/s, v_num=gvyg, loss/val=3.150, accuracy/val=nan.0, loss/train=3.020, accuracy/train=nan.0]






















































Epoch 15: 100%|██████████████████████████████| 196/196 [01:39<00:00,  1.96it/s, v_num=gvyg, loss/val=3.120, accuracy/val=nan.0, loss/train=2.970, accuracy/train=nan.0]





















































Epoch 16: 100%|██████████████████████████████| 196/196 [01:39<00:00,  1.96it/s, v_num=gvyg, loss/val=3.200, accuracy/val=nan.0, loss/train=2.900, accuracy/train=nan.0]






















































Epoch 17: 100%|██████████████████████████████| 196/196 [01:39<00:00,  1.96it/s, v_num=gvyg, loss/val=3.050, accuracy/val=nan.0, loss/train=2.840, accuracy/train=nan.0]





















































Epoch 18: 100%|██████████████████████████████| 196/196 [01:39<00:00,  1.96it/s, v_num=gvyg, loss/val=3.060, accuracy/val=nan.0, loss/train=2.790, accuracy/train=nan.0]






















































Epoch 19: 100%|██████████████████████████████| 196/196 [01:40<00:00,  1.95it/s, v_num=gvyg, loss/val=3.010, accuracy/val=nan.0, loss/train=2.740, accuracy/train=nan.0]





















































Epoch 20: 100%|██████████████████████████████| 196/196 [01:39<00:00,  1.96it/s, v_num=gvyg, loss/val=3.000, accuracy/val=nan.0, loss/train=2.680, accuracy/train=nan.0]






















































Epoch 21: 100%|██████████████████████████████| 196/196 [01:39<00:00,  1.96it/s, v_num=gvyg, loss/val=2.970, accuracy/val=nan.0, loss/train=2.630, accuracy/train=nan.0]






















































Epoch 22: 100%|██████████████████████████████| 196/196 [01:40<00:00,  1.95it/s, v_num=gvyg, loss/val=2.950, accuracy/val=nan.0, loss/train=2.570, accuracy/train=nan.0]






















































Epoch 23: 100%|██████████████████████████████| 196/196 [01:40<00:00,  1.95it/s, v_num=gvyg, loss/val=2.940, accuracy/val=nan.0, loss/train=2.520, accuracy/train=nan.0]






















































Epoch 24: 100%|██████████████████████████████| 196/196 [01:40<00:00,  1.95it/s, v_num=gvyg, loss/val=2.950, accuracy/val=nan.0, loss/train=2.480, accuracy/train=nan.0]





















































Epoch 25: 100%|██████████████████████████████| 196/196 [01:39<00:00,  1.96it/s, v_num=gvyg, loss/val=2.890, accuracy/val=nan.0, loss/train=2.430, accuracy/train=nan.0]






















































Epoch 26: 100%|██████████████████████████████| 196/196 [01:39<00:00,  1.96it/s, v_num=gvyg, loss/val=2.880, accuracy/val=nan.0, loss/train=2.370, accuracy/train=nan.0]





















































Epoch 27: 100%|██████████████████████████████| 196/196 [01:40<00:00,  1.96it/s, v_num=gvyg, loss/val=2.880, accuracy/val=nan.0, loss/train=2.320, accuracy/train=nan.0]






















































Epoch 28: 100%|██████████████████████████████| 196/196 [01:40<00:00,  1.96it/s, v_num=gvyg, loss/val=2.890, accuracy/val=nan.0, loss/train=2.270, accuracy/train=nan.0]






















































Epoch 29: 100%|██████████████████████████████| 196/196 [01:40<00:00,  1.95it/s, v_num=gvyg, loss/val=2.910, accuracy/val=nan.0, loss/train=2.220, accuracy/train=nan.0]





















































Epoch 30: 100%|██████████████████████████████| 196/196 [01:40<00:00,  1.95it/s, v_num=gvyg, loss/val=2.930, accuracy/val=nan.0, loss/train=2.170, accuracy/train=nan.0]






















































Epoch 31: 100%|██████████████████████████████| 196/196 [01:39<00:00,  1.96it/s, v_num=gvyg, loss/val=2.760, accuracy/val=nan.0, loss/train=2.010, accuracy/train=nan.0]






















































Epoch 32: 100%|██████████████████████████████| 196/196 [01:40<00:00,  1.96it/s, v_num=gvyg, loss/val=2.770, accuracy/val=nan.0, loss/train=1.960, accuracy/train=nan.0]





















































Epoch 33: 100%|██████████████████████████████| 196/196 [01:40<00:00,  1.96it/s, v_num=gvyg, loss/val=2.770, accuracy/val=nan.0, loss/train=1.940, accuracy/train=nan.0]






















































Epoch 34: 100%|██████████████████████████████| 196/196 [01:40<00:00,  1.95it/s, v_num=gvyg, loss/val=2.760, accuracy/val=nan.0, loss/train=1.930, accuracy/train=nan.0]






















































Epoch 35: 100%|██████████████████████████████| 196/196 [01:40<00:00,  1.96it/s, v_num=gvyg, loss/val=2.770, accuracy/val=nan.0, loss/train=1.910, accuracy/train=nan.0]






















































Epoch 36: 100%|██████████████████████████████| 196/196 [01:40<00:00,  1.96it/s, v_num=gvyg, loss/val=2.760, accuracy/val=nan.0, loss/train=1.870, accuracy/train=nan.0]





















































Epoch 37: 100%|██████████████████████████████| 196/196 [01:40<00:00,  1.96it/s, v_num=gvyg, loss/val=2.760, accuracy/val=nan.0, loss/train=1.860, accuracy/train=nan.0]






















































Epoch 38: 100%|██████████████████████████████| 196/196 [01:40<00:00,  1.96it/s, v_num=gvyg, loss/val=2.760, accuracy/val=nan.0, loss/train=1.860, accuracy/train=nan.0]






















































Epoch 39: 100%|██████████████████████████████| 196/196 [01:40<00:00,  1.96it/s, v_num=gvyg, loss/val=2.760, accuracy/val=nan.0, loss/train=1.850, accuracy/train=nan.0]



[34m[1m[Val]	 root dir: /home/mmc-server4/Server/Datasets_hdd/tiny-imagenet-200/tiny-imagenet-200/val	 | # of samples: 10,000
Validation DataLoader 0:   0%|                                                                                                                  | 0/20 [00:00<?, ?it/s]
`Trainer.fit` stopped: `max_epochs=40` reached.
Restoring states from the checkpoint path at wandb/aue8088-pa1/vy21gvyg/checkpoints/epoch=0-step=196.ckpt
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2,3]



Validation DataLoader 0: 100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████| 20/20 [00:07<00:00,  2.70it/s]
┏━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━┓
┃[1m      Validate metric      [22m┃[1m       DataLoader 0        [22m┃
┡━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━┩
│[36m       accuracy/val        [39m│[35m            nan            [39m│
│[36m         loss/val          [39m│[35m    4.8815813064575195     [39m│
└───────────────────────────┴───────────────────────────┘